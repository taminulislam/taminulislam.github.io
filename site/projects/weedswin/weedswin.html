<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.551">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Taminul Islam">
<meta name="description" content="WeedSwin hierarchical vision transformer with SAM-2 for multi-stage weed detection and classification">

<title>WeedSwin | Taminul Islam</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em;
  vertical-align: middle;
}
.project-header {
  text-align: center;
  padding: 2rem 0;
  margin-bottom: 2rem;
}
.project-title {
  font-size: 2.5rem;
  font-weight: bold;
  margin-bottom: 1rem;
  
}
.project-subtitle {
  font-size: 1.2rem;
  margin-bottom: 1.5rem;
  opacity: 0.9;
}
.authors {
  font-size: 1.1rem;
  margin-bottom: 0.5rem;
}
.affiliations {
  font-size: 1rem;
  opacity: 0.8;
}
.links-section {
  display: flex;
  justify-content: center;
  gap: 1rem;
  margin: 2rem 0;
  flex-wrap: wrap;
}
.project-link {
  background: transparent;
  color: #495057;
  padding: 0.75rem 1.5rem;
  text-decoration: none;
  border: 2px solid #dee2e6;
  border-radius: 8px;
  font-weight: bold;
  transition: all 0.3s ease;
  display: inline-flex;
  align-items: center;
  gap: 0.5rem;
}
.project-link:hover {
  border-color: #750505;
  color: #750505;
  text-decoration: none;
  transform: translateY(-2px);
}
.journal-badge {
  background: #000000;
  color: white;
  padding: 0.75rem 1.5rem;
  border-radius: 25px;
  font-weight: bold;
  display: inline-block;
  margin: 0 0.5rem;
  cursor: default;
}
.section-title {
  font-size: 1.8rem;
  font-weight: bold;
  margin: 2rem 0 1rem 0;
  color: #011627;
  border-bottom: 3px solid #011627;
  padding-bottom: 0.5rem;
}
.architecture-image {
  width: 100%;
  max-width: 1000px;
  margin: 2rem auto;
  display: block;
  border-radius: 10px;
  box-shadow: 0 4px 15px rgba(0,0,0,0.1);
}
.results-grid {
  display: grid;
  grid-template-columns: repeat(auto-fit, minmax(400px, 1fr));
  gap: 2rem;
  margin: 2rem 0;
}
.result-item {
  text-align: center;
}
.result-image {
  width: 100%;
  border-radius: 10px;
  box-shadow: 0 4px 15px rgba(0,0,0,0.1);
  margin-bottom: 1rem;
}
.abstract-section {
  background: #f8f9fa;
  padding: 2rem;
  border-radius: 10px;
  margin: 2rem 0;
  border-left: 5px solid #750505;
}

/* Mobile Responsive Styles */
@media (max-width: 768px) {
  /* Fix navbar centering on mobile - use flexbox approach */
  .navbar-container {
    display: flex;
    justify-content: space-between;
    align-items: center;
    width: 100%;
  }
  
  .navbar-brand-container {
    flex: 1;
    display: flex;
    justify-content: center;
    margin: 0 !important;
  }
  
  .navbar-toggler {
    order: 3;
    flex-shrink: 0;
  }
  
  /* Add invisible spacer to balance the toggler */
  .navbar-container::before {
    content: '';
    width: 48px; /* Same width as navbar-toggler */
    height: 1px;
    order: 1;
    flex-shrink: 0;
  }
  
  .project-header {
    padding: 1rem 0;
    margin-bottom: 1rem;
  }
  
  .project-title {
    font-size: 1.8rem !important;
    line-height: 1.3;
  }
  
  .authors {
    font-size: 1rem;
  }
  
  .affiliations {
    font-size: 0.9rem;
  }
  
  .section-title {
    font-size: 1.4rem;
    margin: 1.5rem 0 0.8rem 0;
  }
  
  .abstract-section {
    padding: 1.5rem;
    margin: 1.5rem 0;
  }
  
  .links-section {
    gap: 0.8rem;
    margin: 1.5rem 0;
    padding: 0 1rem;
  }
  
  .project-link, .journal-badge {
    padding: 0.6rem 1rem;
    font-size: 0.9rem;
    margin: 0.25rem;
  }
  
  .results-grid {
    grid-template-columns: 1fr;
    gap: 1.5rem;
    margin: 1.5rem 0;
  }
  
  /* Fix main content padding on mobile */
  main.content {
    padding: 0 1rem !important;
  }
  
  /* Responsive images */
  img {
    max-width: 100%;
    height: auto;
  }
  
  /* Adjust image sizes for mobile */
  img[style*="max-width: 800px"] {
    max-width: 95% !important;
  }
  
  img[style*="max-width: 700px"] {
    max-width: 95% !important;
  }
  
  img[style*="max-width: 650px"] {
    max-width: 95% !important;
  }
  
  img[style*="max-width: 600px"] {
    max-width: 95% !important;
  }
  
  /* Better spacing for mobile */
  div[style*="margin: 3rem 0"] {
    margin: 2rem 0 !important;
  }
  
  div[style*="margin: 2rem 0"] {
    margin: 1.5rem 0 !important;
  }
  
  /* Responsive text containers */
  p[style*="max-width: 900px"],
  p[style*="max-width: 1000px"],
  p[style*="max-width: 800px"] {
    max-width: 100% !important;
    padding: 0 0.5rem;
  }
  
  /* Code blocks responsive */
  pre {
    font-size: 0.8rem;
    overflow-x: auto;
  }
  
  /* Button styling for mobile */
  a[style*="background: #750505"] {
    display: block !important;
    width: 100%;
    max-width: 300px;
    margin: 1rem auto !important;
    text-align: center;
  }
}

@media (max-width: 480px) {
  .project-title {
    font-size: 1.5rem !important;
  }
  
  .section-title {
    font-size: 1.2rem;
  }
  
  main.content {
    padding: 0 0.75rem !important;
  }
  
  .abstract-section {
    padding: 1rem;
  }
  
  .project-link, .journal-badge {
    padding: 0.5rem 0.8rem;
    font-size: 0.85rem;
  }
  
  h3[style*="color: #2E8B57"] {
    font-size: 1.1rem !important;
  }
  
  h4[style*="color: #2E8B57"] {
    font-size: 1rem !important;
  }
}
</style>

<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../files/favicon-512.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/all.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/latex-fontsize.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/academicons-1.9.2/all.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/academicons-1.9.2/size.css" rel="stylesheet">

<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-3THLGK2G1N"></script>
<script type="text/javascript">
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-3THLGK2G1N', { 'anonymize_ip': true});
</script>

</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
<header id="quarto-header" class="headroom fixed-top">
  <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
    <!-- <div class="navbar-container container-fluid"> -->
    <div class="navbar-brand-container mx-auto">
      <a class="navbar-brand" href="../../../index.html">
      <span class="navbar-title"><strong>Taminul</strong> Islam</span>
      </a>
    </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
<span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
<li class="nav-item">
  <a class="nav-link" href="../../../index.html"> 
<span class="menu-text">Home</span></a>
</li>  
<li class="nav-item">
  <a class="nav-link" href="../../research/index.html"> 
<span class="menu-text">Publications</span></a>
</li>  
  <li class="nav-item">
    <a class="nav-link" href="../../projects/projects.html"> 
<span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../files/Resume_Taminul.pdf" target="_blank"> 
<span class="menu-text">Resume</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../service/index.html"> 
<span class="menu-text">Service</span></a>
  </li>  
</ul>
          </div>
      </div>
    </nav>
</header>

<div class="project-header">
  <div class="container">
    <h2 class="project-title">WeedSwin hierarchical Vision Transformer with SAM-2 for Multi-stage Weed Detection and Classification</h2>
    
    <div class="authors">
      <strong>Taminul Islam</strong>, Toqi Tahamid Sarker, Khaled R. Ahmed, 
      Cristiana Bernardi Rankrape, Karla Gage
    </div>
    
    <div class="affiliations">
      Southern Illinois University, Carbondale, IL, USA
    </div>
  </div>


<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full">

<main class="content column-page-left container-fluid" id="quarto-document-content" style="max-width: 1200px; margin: 0 auto; padding: 0 2rem; text-align: left;">
  <div class="links-section" style="text-align: center;">
    <span class="journal-badge">Nature: Scientific Reports</span>
    <a href="https://www.nature.com/articles/s41598-025-05092-z" class="project-link" target="_blank">
      <i class="fas fa-file-pdf"></i> Paper
    </a>
    <a href="https://github.com/taminulislam/weedswin" class="project-link" target="_blank">
      <i class="fab fa-github"></i> Code
    </a>
    <a href="https://zenodo.org/records/15808623" class="project-link" target="_blank">
      <i class="fas fa-database"></i> Dataset
    </a>
  </div>

  <div class="abstract-section">
    <h2 class="section-title">Highlights</h2>
    <p>
      Weed detection and classification using computer vision and deep learning techniques have emerged as crucial tools for precision agriculture, 
      offering automated solutions for sustainable farming practices. This study presents a comprehensive approach to weed identification across 
      multiple growth stages, addressing the challenges of detecting and classifying diverse weed species throughout their developmental cycles. 
      We introduce <strong>WeedSwin</strong>, a novel hierarchical vision transformer architecture specifically designed to address the unique 
      challenges of weed detection, such as complex morphological variations and overlapping vegetation patterns.
    </p>
    <p>
      <strong>Key Achievements:</strong>
    </p>
    <ul>
      <li><strong>üìä Outstanding Performance:</strong> WeedSwin achieved <strong>0.993 ¬± 0.004 mAP</strong> and <strong>0.985 mAR</strong> while maintaining practical processing speeds of <strong>218.27 FPS</strong></li>
      <li><strong>üì¶ Comprehensive Datasets:</strong> Two extensive datasets - Alpha Weed Dataset (AWD) with <strong>203,567 images</strong> and Beta Weed Dataset (BWD) with <strong>120,341 images</strong></li>
      <li><strong>üå± Multi-stage Coverage:</strong> Documenting <strong>16 prevalent weed species</strong> across <strong>11 growth stages</strong></li>
      <li><strong>üî¨ Advanced Preprocessing:</strong> Datasets preprocessed using both traditional computer vision techniques and the advanced <strong>SAM-2 model</strong></li>
      <li><strong>üèÜ Competitive Evaluation:</strong> Outperformed DINO Transformer, DETR, EfficientNet B4, YOLO v8, and RetinaNet across various metrics</li>
    </ul>
  </div>

  <h2 class="section-title">üèóÔ∏è WeedSwin Architecture</h2>
  <div style="text-align: center; margin: 2rem 0;">
    <img src="arch.png" alt="WeedSwin Architecture" class="img-fluid" style="max-width: 800px; border-radius: 15px; box-shadow: 0 8px 30px rgba(0,0,0,0.15);">
    <p style="margin-top: 1rem; font-size: 1.1rem; color: #495057; max-width: 900px; margin-left: auto; margin-right: auto;">
      <strong>WeedSwin Hierarchical Architecture:</strong> The novel architecture combines hierarchical vision transformer blocks with 
      spatial attention mechanisms for multi-scale feature extraction. The model processes input images through multiple stages, 
      capturing both fine-grained local features and global contextual information essential for accurate weed detection across 
      different growth stages and environmental conditions.
    </p>
  </div>

  <h2 class="section-title">üéØ Motivation & Challenges</h2>
  <p>
    Weed management has become increasingly critical in modern agriculture, particularly in the diverse agricultural regions of the United States. 
    The challenge of weed invasion extends beyond immediate crop competition, affecting agricultural productivity, economic stability, and ecosystem balance.
  </p>
  <h4 style="color: #2E8B57; margin-top: 1.5rem;">üîç Key Challenges Addressed:</h4>
  <ul>
    <li><strong>üìà Multi-Stage Growth Detection:</strong> Identifying weeds across 11 different growth stages from seedling to maturity</li>
    <li><strong>üåø Species Diversity:</strong> Distinguishing between 16 prevalent weed species with complex morphological variations</li>
    <li><strong>üîÑ Temporal Dynamics:</strong> Handling overlapping vegetation patterns and developmental cycles</li>
    <li><strong>‚ö° Real-time Performance:</strong> Achieving 218.27 FPS for practical field deployment</li>
    <li><strong>üéØ Precision Requirements:</strong> Detecting challenging "driver weeds" that significantly impact agricultural productivity</li>
  </ul>
  <p>
    <strong>WeedSwin Innovation:</strong> Our approach uniquely adapts hierarchical vision transformers with SAM-2 preprocessing to create 
    a robust, scalable solution that outperforms existing architectures while maintaining practical processing speeds.
  </p>

  <div style="text-align: center; margin: 3rem 0;">
    <h3 style="color: #2E8B57; margin-bottom: 1rem;">ü§ñ SAM-2 Integration</h3>
    <img src="cv-sam2.png" alt="SAM-2 Integration" class="img-fluid" style="max-width: 650px; border-radius: 15px; box-shadow: 0 8px 30px rgba(0,0,0,0.15);">
    <p style="margin-top: 1rem; font-size: 1.1rem; color: #495057; max-width: 800px; margin-left: auto; margin-right: auto;">
      <strong>SAM-2 Integration:</strong> Advanced preprocessing using SAM-2 for high-quality annotations with segmentation masks and precise bounding boxes. 
      This innovative approach enhances the dataset quality by providing accurate pixel-level annotations, enabling the WeedSwin model to learn fine-grained 
      features essential for multi-stage weed detection and classification across diverse agricultural environments.
    </p>
  </div>

  <h2 class="section-title">üå± Dataset & Experimental Setup</h2>
  
  <div class="row" style="margin: 3rem 0;">
    <div class="col-lg-6 col-md-12 mb-4" style="text-align: center;">
      <h3 style="color: #2E8B57; margin-bottom: 1rem;">üè† Greenhouse Environment</h3>
      <img src="greenhouse.png" alt="Greenhouse Setup" class="img-fluid" style="border-radius: 15px; box-shadow: 0 8px 30px rgba(0,0,0,0.15);">
      <p style="margin-top: 1rem; font-size: 1rem; color: #495057; text-align: left;">
        <strong>Controlled Greenhouse Environment:</strong> The systematic cultivation setup used for growing and documenting 16 weed species 
        across their complete 11-week lifecycle. This controlled environment ensures consistent conditions for accurate temporal data collection, 
        enabling precise tracking of morphological changes and growth patterns essential for developing robust detection models.
      </p>
    </div>
    
    <div class="col-lg-6 col-md-12 mb-4" style="text-align: center;">
      <h3 style="color: #2E8B57; margin-bottom: 1rem;">üìä Growth Stage Dataset</h3>
      <img src="dataset.png" alt="Dataset Growth Stages" class="img-fluid" style="border-radius: 15px; box-shadow: 0 8px 30px rgba(0,0,0,0.15);">
      <p style="margin-top: 1rem; font-size: 1rem; color: #495057; text-align: left;">
        <strong>Growth Stage Examples:</strong> Representative weed species across 11-week lifecycle. (a,b) AMAPA at week 1 and 11; 
        (c,d) SIDSP at week 1 and 11; (e,f) AMATU at week 1 and 11; (g,h) SETPU at week 1 and 11. These examples illustrate 
        the dramatic morphological changes in plant structure, size, and complexity that the WeedSwin model must accurately detect and classify.
      </p>
    </div>
  </div>

  <h2 class="section-title">üìä Experimental Results & Analysis</h2>
  
  <!-- Main Performance Results -->
  <div style="text-align: center; margin: 3rem 0;">
    <h3 style="color: #2E8B57; margin-bottom: 1rem;">üèÜ Main Performance Results</h3>
    <img src="main_result.png" alt="Main Results" class="img-fluid" style="max-width: 700px; border-radius: 15px; box-shadow: 0 8px 30px rgba(0,0,0,0.15);">
    <p style="margin-top: 1rem; font-size: 1.1rem; color: #495057; max-width: 1000px; margin-left: auto; margin-right: auto;">
      <strong>Outstanding Performance Metrics:</strong> WeedSwin demonstrates superior performance with <strong>0.993 ¬± 0.004 mAP</strong> and 
      <strong>0.985 mAR</strong> scores, significantly outperforming DINO Transformer (ResNet-101 and Swin backbones), DETR, EfficientNet B4, 
      YOLO v8, and RetinaNet across various evaluation metrics. The model maintains exceptional inference speed of <strong>218.27 FPS</strong>, 
      making it highly suitable for real-time agricultural applications.
    </p>
  </div>

  <!-- Detection Examples -->
  <div style="text-align: center; margin: 3rem 0;">
    <h3 style="color: #2E8B57; margin-bottom: 1rem;">üéØ Detection & Classification Examples</h3>
    <img src="detection_result.png" alt="Detection Results" class="img-fluid" style="max-width: 650px; border-radius: 15px; box-shadow: 0 8px 30px rgba(0,0,0,0.15);">
    <p style="margin-top: 1rem; font-size: 1.1rem; color: #495057; max-width: 1000px; margin-left: auto; margin-right: auto;">
      <strong>Multi-Stage Weed Detection:</strong> Qualitative results demonstrate WeedSwin's capability to accurately detect and classify 
      16 weed species across their 11 growth stages. The examples showcase the model's robustness in handling complex morphological variations, 
      overlapping vegetation patterns, and different environmental conditions, particularly excelling in detecting challenging "driver weeds" 
      that significantly impact agricultural productivity.
    </p>
  </div>

  <!-- Comparative Analysis -->
  <div style="text-align: center; margin: 3rem 0;">
    <h3 style="color: #2E8B57; margin-bottom: 1rem;">üìà Comparative Analysis</h3>
    <img src="result_comp.png" alt="Result Comparison" class="img-fluid" style="max-width: 700px; border-radius: 15px; box-shadow: 0 8px 30px rgba(0,0,0,0.15);">
    <p style="margin-top: 1rem; font-size: 1.1rem; color: #495057; max-width: 1000px; margin-left: auto; margin-right: auto;">
      <strong>Comprehensive Benchmark Comparison:</strong> Detailed performance analysis against state-of-the-art object detection architectures 
      including DINO Transformer with ResNet-101 and Swin backbones, Detection Transformer (DETR), EfficientNet B4, YOLO v8, and RetinaNet. 
      The comparison reveals WeedSwin's consistent superiority across different growth stages, with particularly notable improvements in 
      detecting early-stage weeds and handling temporal dynamics throughout the growing season.
    </p>
  </div>

  <!-- Ablation Study -->
  <div style="text-align: center; margin: 3rem 0;">
    <h3 style="color: #2E8B57; margin-bottom: 1rem;">üî¨ Ablation Study Analysis</h3>
    <img src="ablation.png" alt="Ablation Study" class="img-fluid" style="max-width: 700px; border-radius: 15px; box-shadow: 0 8px 30px rgba(0,0,0,0.15);">
    <p style="margin-top: 1rem; font-size: 1.1rem; color: #495057; max-width: 1000px; margin-left: auto; margin-right: auto;">
      <strong>Component-wise Architecture Analysis:</strong> Systematic ablation study revealing the contribution of each WeedSwin component 
      to the overall performance. The analysis demonstrates the effectiveness of the hierarchical transformer design, the impact of 
      SAM-2 preprocessing, and the importance of multi-scale feature extraction in achieving state-of-the-art results. Results show improved 
      accuracy as plants mature, validating the robustness of the temporal modeling approach.
    </p>
  </div>

  <h2 class="section-title">üöÄ Key Contributions & Impact</h2>
  <div class="row">
    <div class="col-lg-6 col-md-12 mb-4">
      <h4 style="color: #2E8B57;">üî¨ Technical Innovations:</h4>
      <ul>
        <li><strong>üèóÔ∏è Novel WeedSwin Architecture:</strong> First hierarchical vision transformer specifically designed for multi-stage weed detection and classification</li>
        <li><strong>ü§ñ SAM-2 Integration:</strong> Advanced preprocessing pipeline using SAM-2 for high-quality annotations with precise segmentation masks</li>
        <li><strong>üìä Comprehensive Datasets:</strong> Two extensive datasets (AWD: 203,567 images, BWD: 120,341 images) covering 16 weed species across 11 growth stages</li>
        <li><strong>‚ö° Performance Excellence:</strong> Achieved 0.993 ¬± 0.004 mAP and 0.985 mAR with 218.27 FPS processing speed</li>
      </ul>
    </div>
    <div class="col-lg-6 col-md-12 mb-4">
      <h4 style="color: #2E8B57;">üåç Practical Impact:</h4>
      <ul>
        <li><strong>üéØ Real-time Deployment:</strong> Fast inference suitable for practical agricultural automation systems</li>
        <li><strong>üå± Multi-stage Capability:</strong> Robust detection across complete weed developmental cycles from seedling to maturity</li>
        <li><strong>üèÜ State-of-the-art Results:</strong> Outperformed DINO, DETR, EfficientNet B4, YOLO v8, and RetinaNet architectures</li>
        <li><strong>üåø Sustainable Agriculture:</strong> Enables precision weed management for reduced herbicide usage and environmental impact</li>
      </ul>
    </div>
  </div>
  
  <div style="background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%); padding: 2rem; border-radius: 15px; margin: 2rem 0; border-left: 5px solid #2E8B57;">
    <h4 style="color: #011627; margin-bottom: 1rem;">üéØ Research Significance</h4>
    <p style="font-size: 1.05rem; line-height: 1.7; margin-bottom: 0;">
      This research establishes a foundation for more efficient and environmentally sustainable weed management practices. 
      The demonstrated success of the WeedSwin architecture, combined with extensive temporal datasets, represents a significant 
      advancement in agricultural computer vision, supporting the evolution of precision farming techniques while promoting 
      reduced herbicide usage and improved crop management efficiency.
    </p>
  </div>

  <h2 class="section-title">üìù Citation</h2>
  <div class="abstract-section">
    <p style="margin-bottom: 1rem; font-size: 1.05rem; color: #495057;">
      If you find WeedSwin useful in your research, please consider citing our paper:
    </p>
    <pre><code>@article{islam2025weedswin,
  title={WeedSwin hierarchical vision transformer with SAM-2 for multi-stage weed detection and classification},
  author={Islam, Taminul and Sarker, Toqi Tahamid and Ahmed, Khaled R and Rankrape, Cristiana Bernardi and Gage, Karla},
  journal={Scientific Reports},
  volume={15},
  number={1},
  pages={23274},
  year={2025},
  publisher={Nature Publishing Group UK London}
}</code></pre>
    <div style="margin-top: 1rem; padding: 1rem; background: #f0f8f0; border-radius: 8px; border-left: 4px solid #2E8B57;">
      <p style="margin: 0; font-size: 0.95rem; color: #2d5a3d;">
        <strong>üìñ Paper:</strong> <a href="https://www.nature.com/articles/s41598-025-05092-z" target="_blank" style="color: #2E8B57; text-decoration: none; font-weight: 600;">Scientific Reports (Nature) - Volume 15, Article 23274 (2025)</a><br>
        <strong>üîó DOI:</strong> <span style="font-family: monospace;">10.1038/s41598-025-05092-z</span>
      </p>
    </div>
  </div>

  <h2 class="section-title">üìã Conference Poster</h2>
  <div style="text-align: center; margin: 3rem 0;">
    <h3 style="color: #2E8B57; margin-bottom: 1rem;">üåø WeedVision: Early Project Development</h3>
    <p style="margin-bottom: 2rem; font-size: 1.05rem; color: #495057; max-width: 800px; margin-left: auto; margin-right: auto;">
      This poster presents the early development of our weed detection research, initially called "WeedVision," which evolved into the 
      comprehensive WeedSwin project. The poster showcases the foundational work that led to our current state-of-the-art approach.
    </p>
    
    <div style="position: relative; display: inline-block;">
      <img src="poster/weed.png" alt="WeedVision Conference Poster" class="img-fluid" style="max-width: 600px; border-radius: 15px; box-shadow: 0 8px 30px rgba(0,0,0,0.15); cursor: pointer;" onclick="window.open('poster/weeds_poster.pdf', '_blank')">
      <div style="position: absolute; bottom: 15px; right: 15px; background: rgba(0,0,0,0.8); color: white; padding: 0.5rem 1rem; border-radius: 8px; font-size: 0.9rem;">
        <i class="fas fa-download"></i> Click to view PDF
      </div>
    </div>
    
    <div style="margin-top: 1.5rem;">
      <a href="poster/weeds_poster.pdf" target="_blank" style="background: #750505; color: white; padding: 0.75rem 1.5rem; text-decoration: none; border-radius: 8px; font-weight: bold; display: inline-flex; align-items: center; gap: 0.5rem; transition: all 0.3s ease;">
        <i class="fas fa-file-pdf"></i> Download Full Resolution Poster (PDF)
      </a>
    </div>
    
    <p style="margin-top: 1rem; font-size: 0.95rem; color: #6c757d; font-style: italic;">
      WeedVision poster presented at academic conference showcasing the preliminary research that evolved into the WeedSwin project
    </p>
  </div>

</main>

</div>

<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p><span class="faux-block"><i class="fa-brands fa-creative-commons" aria-label="creative-commons"></i> 2025 Taminul Islam</span></p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>

</body></html>